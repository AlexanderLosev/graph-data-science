[[algorithms-embeddings-fastrp]]
= Fast Random Projection
:entity: node
:result: embedding
:algorithm: FastRP

[abstract]
--
This section describes the Fast Random Projection (FastRP) node embedding algorithm in the Neo4j Graph Data Science library.
--

This topic includes:

* <<algorithms-embeddings-fastrp-introduction, Introduction>>
* <<algorithms-embeddings-fastrp-parameter-tuning, Tuning algorithm parameters>>
* <<algorithms-embeddings-fastrp-syntax, Syntax>>
** <<algorithms-embeddings-fastrp-syntax-anonymous, Anonymous graphs>>
* <<algorithms-embeddings-fastrp-examples, Examples>>
** <<algorithms-embeddings-fastrp-examples-memory-estimation, Memory Estimation>>
** <<algorithms-embeddings-fastrp-examples-stream, Stream>>
** <<algorithms-embeddings-fastrp-examples-stats, Stats>>
** <<algorithms-embeddings-fastrp-examples-mutate, Mutate>>
** <<algorithms-embeddings-fastrp-examples-write, Write>>
** <<algorithms-embeddings-fastrp-examples-weighted, Weighted>>


[[algorithms-embeddings-fastrp-introduction]]
== Introduction

Fast Random Projection, or FastRP for short, is a node embedding algorithm in the family of random projection algorithms.
These algorithms are theoretically backed by the Johnsson-Lindenstrauss lemma according to which one can project _n_ vectors of _arbitrary_ dimension into _O(log(n))_ dimensions and still approximately preserve pairwise distances among the points.
In fact, a linear projection chosen in a random way satisfies this property.

Such techniques therefore allow for aggressive dimensionality reduction while preserving most of the distance information.
The FastRP algorithm operates on graphs, in which case we care about preserving similarity between nodes and their neighbors.
This means that two nodes that have similar neighborhoods should be assigned similar embedding vectors.
Conversely, two nodes that are not similar should be not be assigned similar embedding vectors.

The FastRP algorithm initially assigns random vectors to all nodes using a technique called _very sparse random projection_, see (Achlioptas, 2003) below.
The algorithm then iteratively constructs _intermediate_ embeddings by averaging either neighboring intermediate embeddings from the previous iteration, or the generated random vectors during the first iteration.
In each iteration, the intermediate embedding is normalised using a https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm[standard euclidean norm].
That is, each element in the embedding is divided by the square root of the sum of squares of the emdedding elements.

In the end, the resulting embedding for each node is a weighted sum of the intermediate embeddings, where the weights are a configuration parameter called `iterationWeights`.

Therefore, each node's embedding depends on a neighborhood of radius equal to the number of iterations.
This way FastRP exploits higher-order relationships in the graph while still being highly scalable.

The present implementation extends the original algorithm to support weighted graphs, which computes weighted averages of neighboring embeddings using the relationship weights.
In order to make use of this, the `relationshipWeightProperty` parameter should be set to an existing relationship property.

The original algorithm is intended only for undirected graphs.
We support running on both on directed graphs and undirected graph.
For directed graphs we consider only the outgoing neighbors when computing the intermediate embeddings for a node.
Therefore, using the orientations `NATURAL`, `REVERSE` or `UNDIRECTED` will all give different embeddings.
In general, it is recommended to first use `UNDIRECTED` as this is what the original algorithm was evaluated on.

For more information on this algorithm see:

* https://arxiv.org/pdf/1908.11512.pdf[H. Chen, S.F. Sultan, Y. Tian, M. Chen, S. Skiena: Fast and Accurate Network Embeddings via Very Sparse Random Projection, 2019.^]
* https://core.ac.uk/download/pdf/82724427.pdf[Dimitris Achlioptas. Database-friendly random projections: Johnson-Lindenstrauss with binary coins. Journal of Computer and System Sciences, 66(4):671â€“687, 2003.]


[[algorithms-embeddings-fastrp-parameter-tuning]]
== Tuning algorithm parameters

In order to improve the embedding quality using FastRP on one of your graphs, it is possible to tune the algorithm parameters.
This process of finding the best parameters for your specific use case and graph is typically referred to as https://en.wikipedia.org/wiki/Hyperparameter_optimization[hyperparameter tuning].
We will go through each of the configuration parameters and explain how they behave.

For statistically sound results, it is a good idea to reserve a test set excluded from parameter tuning.
After selecting a set of parameter values, the embedding quality can be evaluated using a downstream machine learning task on the test set.
By varying the parameter values and studying the precision of the machine learning task, it is possible to deduce the parameter values that best fit the concrete dataset and use case.
To construct such a set you may want to use a dedicated node label in the graph to denote a subgraph without the test data.


=== Embedding dimension

The embedding dimension is the length of the produced vectors.
A greater dimension offers a greater precision, but is more costly to operate over.

The optimal embedding dimension depends on the number of nodes in the graph.
Since the amount of information the embedding can encode is limited by its dimension, a larger graph will tend to require a greater embedding dimension.
A typical value is a power of two in the range 128 - 1024.
A value of at least 256 gives good results on graphs in the order of 10^5^ nodes, but in general increasing the dimension improves results.
Increasing embedding dimension will however increase memory requirements and runtime linearly.


=== Normalization strength

The normalization strength is used to control how node degrees influence the embedding.
Using a negative value will downplay the importance of high degree neighbors, while a positive value will instead increase their importance.
The optimal normalization strength depends on the graph and on the task that the embeddings will be used for.
In the original paper, hyperparameter tuning was done in the range of `[-1,0]` (no positive values), but we have found cases where a positive normalization strengths gives better results.


=== Iteration weights

The iteration weights parameter control two aspects: the number of iterations, and their relative impact on the final node embedding.
The parameter is a list of numbers, indicating one iteration per number where the number is the weight applied to that iteration.

In each iteration, the algorithm will expand across all relationships in the graph.
This has some implications:

* With a single iteration, only direct neighbors will be considered for each node embedding.
* With two iterations, direct neighbors and second-degree neighbors will be considered for each node embedding.
* With three iterations, direct neighbors, second-degree neighbors, and third-degree neighbors will be considered for each node embedding.
Direct neighbors may be reached twice, in different iterations.
* In general, the embedding corresponding to the `i`:th iteration contains features depending on nodes reachable with paths of length `i`.
If the graph is undirected, then a node reachable with a path of length `L` can also be reached with length `L+2k`, for any integer `k`.
* In particular, a node may reach back to itself on each even iteration (depending on the direction in the graph).

It is good to have at least one non-zero weight in an even and in an odd position.
Typically, using at least a few iterations, for example three, is recommended.
However, a too high value will consider nodes far away and may not be informative or even be detrimental.
The intuition here is that as the projections reach further away from the node, the less specific the neighborhood becomes.
Of course, a greater number of iterations will also take more time to complete.


=== Orientation

Choosing the right orientation when creating the graph may have the single greatest impact.
The FastRP algorithm is designed to work with undirected graphs, and we expect this to be the best in most cases.
If you expect only outgoing or incoming relationships to be informative for a prediction task, then you may want to try using the orientations `NATURAL` or `REVERSE` respectively.


[[algorithms-embeddings-fastrp-syntax]]
== Syntax

include::../shared/syntax-intro-named-graph.adoc[]

.FastRP syntax per mode
[.tabbed-example]
====

[.include-with-stream]
======

.Run FastRP in stream mode on a named graph.
[source, cypher]
----
CALL gds.fastRP.stream(
  graphName: String,
  configuration: Map
) YIELD
  nodeId: Integer,
  embedding: List<Float>
----

include::../common-configuration/common-parameters-named-graph.adoc[]

include::../common-configuration/common-stream-stats-configuration-named-graph.adoc[]

include::specific-configuration.adoc[]

.Results
[opts="header"]
|===
| Name      | Type         | Description
| nodeId    | Integer      | Node ID.
| embedding | List<Float>  | FastRP node embedding.
|===
======

[.include-with-stats]
======

.Run FastRP in stats mode on a named graph.
[source, cypher]
----
CALL gds.fastRP.stats(
  graphName: String,
  configuration: Map
) YIELD
  nodeCount: Integer,
  createMillis: Integer,
  computeMillis: Integer,
  configuration: Map
----

include::../common-configuration/common-parameters-named-graph.adoc[]

include::../common-configuration/common-stream-stats-configuration-named-graph.adoc[]

include::specific-configuration.adoc[]

.Results
[opts="header",cols="1,1,6"]
|===
| Name          | Type    | Description
| nodeCount     | Integer | Number of nodes processed.
| createMillis  | Integer | Milliseconds for creating the graph.
| computeMillis | Integer | Milliseconds for running the algorithm.
| configuration | Map     | Configuration used for running the algorithm.
|===

======

[.include-with-mutate]
======

.Run FastRP in mutate mode on a named graph.
[source, cypher]
----
CALL gds.fastRP.mutate(
  graphName: String,
  configuration: Map
) YIELD
  nodeCount: Integer,
  nodePropertiesWritten: Integer,
  createMillis: Integer,
  computeMillis: Integer,
  mutateMillis: Integer,
  configuration: Map
----

include::../common-configuration/common-parameters-named-graph.adoc[]

include::../common-configuration/common-mutate-configuration-named-graph.adoc[]

include::specific-configuration.adoc[]

.Results
[opts="header"]
|===
| Name                  | Type    | Description
| nodeCount             | Integer | Number of nodes processed.
| nodePropertiesWritten | Integer | Number of node properties written.
| createMillis          | Integer | Milliseconds for creating the graph.
| computeMillis         | Integer | Milliseconds for running the algorithm.
| mutateMillis          | Integer | Milliseconds for adding properties to the in-memory graph.
| configuration         | Map     | Configuration used for running the algorithm.
|===
======

[.include-with-write]
======

.Run FastRP in write mode on a named graph.
[source, cypher]
----
CALL gds.fastRP.write(
  graphName: String,
  configuration: Map
) YIELD
  nodeCount: Integer,
  propertiesWritten: Integer,
  createMillis: Integer,
  computeMillis: Integer,
  writeMillis: Integer,
  configuration: Map
----

include::../common-configuration/common-parameters-named-graph.adoc[]

include::../common-configuration/common-write-configuration-named-graph.adoc[]

include::specific-configuration.adoc[]

.Results
[opts="header"]
|===
| Name                  | Type    | Description
| nodeCount             | Integer | Number of nodes processed.
| nodePropertiesWritten | Integer | Number of node properties written.
| createMillis          | Integer | Milliseconds for creating the graph.
| computeMillis         | Integer | Milliseconds for running the algorithm.
| writeMillis           | Integer | Milliseconds for writing result data back to Neo4j.
| configuration         | Map     | Configuration used for running the algorithm.
|===

======

====


[[algorithms-embeddings-fastrp-syntax-anonymous]]
=== Anonymous graphs

include::../shared/syntax-anonymous-graphs.adoc[]

.Run FastRP in write mode on an anonymous graph.
[source, cypher]
----
CALL gds.fastRP.write(
  configuration: Map
)
YIELD
  nodeCount: Integer,
  nodePropertiesWritten: Integer,
  createMillis: Integer,
  computeMillis: Integer,
  writeMillis: Integer,
  configuration: Map
----

include::../common-configuration/common-configuration-anonymous-graph.adoc[]

include::specific-configuration.adoc[]

The results are the same as for running write mode with a named graph, see the <<algorithms-embeddings-fastrp-syntax, write mode syntax above>>.


[[algorithms-embeddings-fastrp-examples]]
== Examples

:algorithm-name: FastRP node embedding
include::../shared/examples-intro.adoc[]

Consider the graph created by the following Cypher statement:

[source, cypher, role=setup-query]
----
CREATE
  (dan:Person {name: 'Dan'}),
  (annie:Person {name: 'Annie'}),
  (matt:Person {name: 'Matt'}),
  (jeff:Person {name: 'Jeff'}),
  (brie:Person {name: 'Brie'}),
  (elsa:Person {name: 'Elsa'}),
  (john:Person {name: 'John'}),

  (dan)-[:KNOWS {weight: 1.0}]->(annie),
  (dan)-[:KNOWS {weight: 1.0}]->(matt),
  (annie)-[:KNOWS {weight: 1.0}]->(matt),
  (annie)-[:KNOWS {weight: 1.0}]->(jeff),
  (annie)-[:KNOWS {weight: 1.0}]->(brie),
  (matt)-[:KNOWS {weight: 3.5}]->(brie),
  (brie)-[:KNOWS {weight: 1.0}]->(elsa),
  (brie)-[:KNOWS {weight: 2.0}]->(jeff),
  (john)-[:KNOWS {weight: 1.0}]->(jeff);
----

This graph represents seven people who know one another.
A relationship property `weight` denotes the strength of the knowledge between two persons.

With the graph in Neo4j we can now project it into the graph catalog to prepare it for algorithm execution.
We do this using a native projection targeting the `Person` nodes and the `KNOWS` relationships.
For the relationships we will use the `UNDIRECTED` orientation.
This is because the FastRP algorithm has been measured to compute more predictive node embeddings in undirected graphs.
We will also add the `weight` relationship property which we will make use of when running the weighted version of FastRP.

include::../shared/examples-named-native-note.adoc[]

.The following statement will create a graph using a native projection and store it in the graph catalog under the name 'persons'.
[source, cypher, role=graph-create-query]
----
CALL gds.graph.create(
  'persons',
  'Person',
  {
    KNOWS: {
      orientation: 'UNDIRECTED',
      properties: 'weight'
    }
})
----


[[algorithms-embeddings-fastrp-examples-memory-estimation]]
=== Memory Estimation

:mode: stream
include::../shared/examples-estimate-intro.adoc[]

[role=query-example]
--
.The following will estimate the memory requirements for running the algorithm:
[source, cypher]
----
CALL gds.fastRP.stream.estimate('persons', {embeddingDimension: 128})
YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory
----

.Results
[opts="header", cols="1,1,1,1,1"]
|===
| nodeCount | relationshipCount | bytesMin | bytesMax | requiredMemory
| 7         | 18                | 11392    | 11392    | "11392 Bytes"
|===
--


[[algorithms-embeddings-fastrp-examples-stream]]
=== Stream

:stream-details: For example, we can collect the results and pass them into a similarity algorithm.
include::../shared/examples-stream-intro.adoc[]

[role=query-example, no-result=true]
--
.The following will run the algorithm, and stream results:
[source, cypher]
----
CALL gds.fastRP.stream('persons', { embeddingDimension: 3 })
YIELD nodeId, embedding
----

[opts=header]
.Results
|===
| nodeId | embedding
| 0      | [-1.0168722, 2.000039, 0.8686633]
| 1      | [-1.1853837, 2.0166488, 0.55430746]
| 2      | [-0.64757454, 2.254217, 0.2790558]
| 3      | [0.054054752, 2.2928863, 0.2753105]
| 4      | [-1.2682186, 1.7526158, 0.9458506]
| 5      | [-0.42385957, 2.2773507, 0.20764782]
| 6      | [-1.1808083, 1.5593154, 0.6784344]
|===
--

The results of the algorithm are not very intuitively interpretable, as the node embedding format is a mathematical abstraction of the node within its neighborhood, designed for machine learning programs.
What we can see is that the embeddings have three elements (as configured using `embeddingDimension`) and that the numbers are relatively small (they all fit in the range of `[-2, 3]`).
The magnitude of the numbers is controlled by the `embeddingDimension`, the number of nodes in the graph, and by the fact that FastRP performs euclidean normalization on the intermediate embedding vectors.

[NOTE]
====
Due to the random nature of the algorithm the results will vary between the runs.
However, this does not necessarily mean that the pairwise distances of two node embeddings vary as much.
====


[[algorithms-embeddings-fastrp-examples-stats]]
=== Stats

:stats-syntax: algorithms-embeddings-fastrp-syntax
include::../shared/examples-stats-intro.adoc[]

[role=query-example]
--
.The following will run the algorithm and returns the result in form of statistical and measurement values
[source, cypher]
----
CALL gds.fastRP.stats('persons', { embeddingDimension: 3 })
YIELD nodeCount
----

[opts=header]
.Results
|===
| nodeCount
| 7
|===
--

The `stats` mode does not currently offer any statistical results for the embeddings themselves.
We can however see that the algorithm has successfully processed all seven nodes in our example graph.


[[algorithms-embeddings-fastrp-examples-mutate]]
=== Mutate

[role=query-example, no-result=true]
--
.The following will run the algorithm in `mutate` mode:
[source, cypher]
----
CALL gds.fastRP.mutate(
  'persons',
  {
    iterationWeights: [0.0, 0.34, 2.1],
    embeddingDimension: 3,
    normalizationStrength: -0.71,
    mutateProperty: 'embedding'
  }
)
YIELD nodePropertiesWritten, mutateMillis

----

[opts=header]
.Results
|===
| nodePropertiesWritten | mutateMillis
| 7                     | 0
|===
--


[[algorithms-embeddings-fastrp-examples-write]]
=== Write

[role=query-example, no-result=true]
--
.The following will run the algorithm in `write` mode:
[source, cypher]
----
CALL gds.fastRP.write(
  'persons',
  {
    iterationWeights: [0.0, 0.34, 2.1],
    embeddingDimension: 3,
    normalizationStrength: -0.71,
    writeProperty: 'embedding'
  }
)
YIELD nodePropertiesWritten, writeMillis

----

[opts=header]
.Results
|===
| nodePropertiesWritten | mutateMillis
| 7                     | 212
|===
--


[[algorithms-embeddings-fastrp-examples-weighted]]
=== Weighted

[role=query-example, no-result=true]
--
.The following will run the algorithm, and stream results:
[source, cypher]
----
CALL gds.fastRP.stream(
  'persons',
  {
    iterationWeights: [0.0, 0.34, 2.1],
    embeddingDimension: 3,
    normalizationStrength: -0.71,
    relationshipWeightProperty: 'weight'
  }
)
YIELD nodeId, embedding
----

[opts=header]
.Results
|===
| nodeId | embedding
| 0      | [-1.9220695495605469,0.8281561136245728,-0.23398679494857788]
| 1      | [-0.9239899516105652,1.9944313764572144,-0.5190169811248779]
| 2      | [-0.8023543953895569,2.028059959411621,0.4712531268596649]
| 3      | [-1.2199127674102783,1.1800869703292847,1.1962001323699951]
| 4      | [-1.746078610420227,0.5176445245742798,-0.9333235621452332]
| 5      | [0.0782150849699974,1.6632782220840454,0.7139096260070801]
| 6      | [-0.8536702990531921,1.0019549131393433,-1.374551773071289]
|===
--
