[[algorithms-embeddings-random-projection]]
[.alpha]
= Random Projection

[abstract]
--
This section describes the Random Projection node embedding algorithm in the Neo4j Graph Data Science library.
--

This topic includes:

* <<algorithms-embeddings-random-projection-introduction, Introduction>>
* <<algorithms-embeddings-random-projection-syntax, Syntax>>
* <<algorithms-embeddings-fastrp-parameter-tuning, Hyperparameter tuning>>
* <<algorithms-embeddings-random-projection-examples, Examples>>


[[algorithms-embeddings-random-projection-introduction]]
== Introduction

Random Projection is a node embedding algorithm in the family of random projection algorithms.
These algorithms are theoretically backed by the Johnsson-Lindenstrauss lemma according to which, one can project _n_ vectors of _arbitrary_ dimension into _O(log(n))_ dimensions and still approximately preserve pairwise distances among the points.
In fact the projection is linear and can be chosen in a random way.

Such techniques therefore allow for aggressive dimensionality reduction while preserving most of the distance information.
The Random Projection operates on graphs, in which case we care about preserving similarity between nodes and their neighbors.
This means that two nodes that have similar neighborhoods should be assigned similar embedding vectors.
Conversely, two nodes that are not similar should be not be assigned similar embedding vectors.

The Random Projection algorithm initially assigns random vectors to all nodes using a technique called _very sparse random projection_, see (Achlioptas, 2003) below.
The algorithm then iteratively constructs _intermediate_ embeddings by averaging neighboring intermediate embeddings from the previous iteration, or the generated random vectors during the first iteration.

In the end, the resulting embedding for each node is a weighted sum of the intermediate embeddings, where the weights are a configuration parameter called `iterationWeights`.

Therefore, each node's embedding depends on a neighborhood of radius equal to the number of iterations.
This way Random Projection exploits higher-order relationships in the graph while still being highly scalable.

The present implementation extends the original algorithm to support weighted graphs, which computes weighted averages of neighboring embeddings using the relationship weights.
In order to make use of this, the `relationshipWeightProperty` parameter should be set to an existing relationship property.

The original algorithm is intended only for undirected graphs.
We support running on both on directed graphs and undirected graph.
For directed graphs we consider only the outgoing neighbors when computing the intermediate embeddings for a node.
Therefore, using the orientations NATURAL, REVERSE and UNDIRECTED will all give different embeddings.
In general, it is recommended to first use UNDIRECTED as this is what the original algorithm was evaluated on.

For more information on this algorithm see:

* https://arxiv.org/pdf/1908.11512.pdf[H. Chen, S.F. Sultan, Y. Tian, M. Chen, S. Skiena: Fast and Accurate Network Embeddings via Very Sparse Random Projection, 2019.^]
* https://core.ac.uk/download/pdf/82724427.pdf[Dimitris Achlioptas. Database-friendly random projections: Johnson-Lindenstrauss with binary coins. Journal of Computer and System Sciences, 66(4):671â€“687, 2003.]


[[algorithms-embeddings-random-projection-syntax]]
== Syntax

.Random Projection syntax per mode
[.tabbed-example]
====

[.include-with-stream]
======
.Run Random Projection in stream mode on a named graph.
[source, cypher]
----
CALL gds.alpha.randomProjection.stream(
  graphName: String,
  configuration: Map
) YIELD
  nodeId: Integer,
  embedding: List<Float>
----

include::../../common-configuration/common-parameters-named-graph.adoc[]

include::../../common-configuration/common-stream-stats-configuration-named-graph.adoc[]

include::specific-configuration.adoc[]

.Results
[opts="header",cols="1m,1,6"]
|===
| Name      | Type         | Description
| nodeId    | Integer      | The Neo4j node ID.
| embedding | List<Float>  | The computed node embedding.
|===
======

[.include-with-write]
======
.Run Random Projection in write mode on a graph stored in the catalog.
[source, cypher]
----
CALL gds.alpha.randomProjection.write(
  graphName: String,
  configuration: Map
)
YIELD
  nodeCount: Integer,
  propertiesWritten: Integer,
  createMillis: Integer,
  computeMillis: Integer,
  writeMillis: Integer,
  configuration: Map
----

include::../../common-configuration/common-parameters-named-graph.adoc[]

include::../../common-configuration/common-stream-stats-configuration-named-graph.adoc[]

include::specific-configuration.adoc[]

.Results
[opts="header",cols="1,1,6"]
|===
| Name               | Type                 | Description
| nodeCount          | Integer              | The number of nodes processed.
| propertiesWritten  | Integer              | The number of node properties written.
| createMillis       | Integer              | Milliseconds for loading data.
| computeMillis      | Integer              | Milliseconds for running the algorithm.
| writeMillis        | Integer              | Milliseconds for writing result data back to Neo4j.
| configuration      | Map                  | The configuration used for running the algorithm.
|===
======
====


[[algorithms-embeddings-random-projection-syntax-anonymous]]
=== Anonymous graphs

include::../../shared/syntax-anonymous-graphs.adoc[]

.Run Random Projection in write mode on an anonymous graph.
[source, cypher]
----
CALL gds.alpha.randomProjection.write(
  configuration: Map
)
YIELD
  nodeCount: Integer,
  propertiesWritten: Integer,
  createMillis: Integer,
  computeMillis: Integer,
  writeMillis: Integer,
  configuration: Map
----

include::../../common-configuration/common-configuration-anonymous-graph.adoc[]

include::specific-configuration.adoc[]

The results are the same as for running write mode with a named graph, see the <<algorithms-embeddings-random-projection-syntax, write mode syntax above>>.


[[algorithms-embeddings-fastrp-parameter-tuning]]
== Tuning algorithm parameters

In order to improve the embedding quality using Random Projection on one of your graphs, it is possible to tune the algorithm parameters.
This process of finding the best parameters for your specific use case and graph is typically referred to as https://en.wikipedia.org/wiki/Hyperparameter_optimization[hyperparameter tuning].
We will go through each of the configuration parameters and explain how they behave.

For statistically sound results, it is a good idea to reserve a test set excluded from parameter tuning.
After hyperparameter tuning has been made, the embedding with the best settings can then be evaluated using a downstream machine learning task on the test set.
To construct such a set you may want to create a node label in the graph using cypher that represents a subgraph without the test data.

=== Embedding Dimension

The optimal value for `embeddingSize` depends on the number of nodes in the graph.
Since the amount of information the embedding can encode is limited by the `embeddingSize`, a larger graph will tend to require a higher embedding dimension.
A typical value is a power of two in the range 128 - 1024.
A value of at least 256 gives good results on graphs with as many as 200000 nodes, but in general increasing the dimension improves results.
Increasing embedding dimension will however increase memory requirements and runtime linearly.

=== Normalization strength
Using a negative value for normalization strength will downplay the importance of high degree neighbors when constructing the embeddings.
A positive value will instead increase their importance.
The optimal normalization strength depends on the graph and on the task that the embeddings will be used for.
In the original paper, hyperparameter tuning was done one the range `[-1,0]`, but we have found a case where slightly positive normalization strength gave better results.

=== Iteration weights
By selecting `iterationWeights`, it is possible both to set the number of iterations and the weight given to the embedding resulting from each iteration.
The embedding corresponding to the `i`:th iteration contains features depending on nodes reachable with paths of distance `i`.
If the graph is undirected, then a node reachable with a path of length `L` can also be reached with length `L+2k`.
Therefore, the third iteration for example, will contain features depending both on direct neighbors and nodes at distance three.
It is good to have at least one non-zero weight in an even and in an odd position.
Typically, using at least a few iterations, for example three, is recommended.
However, a too high value will consider nodes far away and may not be informative.

=== Orientation
Choosing the right orientation when creating the graph may have the single biggest impact.
The Random Projection algorithm is designed only to work with undirected graphs, and we expect this to be the best in most cases.
If you expect only outgoing or incoming relationships to be informative for a prediction task, then you may want to try using the orientations `NATURAL` or `REVERSE` respectively.


[[algorithms-embeddings-random-projection-examples]]
== Examples

Consider the graph created by the following Cypher statement:

[source, cypher, role=setup-query]
----
CREATE
  (Dan:Person),
  (Annie:Person),
  (Matt:Person),
  (Jeff:Person),
  (Brie:Person),
  (Elsa:Person),
  (John:Person),

  (Dan)-[:REL]->(Annie),
  (Dan)-[:REL]->(Matt),
  (Annie)-[:REL]->(Matt),
  (Annie)-[:REL]->(Jeff),
  (Annie)-[:REL]->(Brie),
  (Matt)-[:REL]->(Brie),
  (Brie)-[:REL]->(Elsa),
  (Brie)-[:REL]->(Jeff),
  (John)-[:REL]->(Jeff);
----

[source, cypher, role=graph-create-query]
----
CALL gds.graph.create(
  'persons',
  'Person',
  {
    REL: {
      orientation: 'UNDIRECTED'
    }
})
----


=== Stream

[source, cypher, role=query-example, no-result=true]
----
CALL gds.alpha.randomProjection.stream(
  'persons',
  {
    iterationWeights: [1.0, 1.0, 4.0],
    embeddingSize: 3,
    normalizationStrength: -0.9
  }
)
----

[opts=header]
.Results
|===
| nodeId | embedding
| 0      | [4.898722171783447,-2.360605239868164,-0.005474746227264404]
| 1      | [4.2204999923706055,-3.6900253295898438,1.4258460998535156]
| 2      | [2.1105315685272217,-4.533860206604004,1.5421669483184814]
| 3      | [1.578028917312622,-3.608323574066162,-2.6669602394104004]
| 4      | [4.866636753082275,-1.8121209144592285,0.38477471470832825]
| 5      | [0.9328402280807495,-3.445551633834839,3.0306806564331055]
| 6      | [4.526181221008301,-0.7839458584785461,-0.5074502825737]
|===

[NOTE]
====
Due to the random nature of the algorithm the results will vary between the runs.
However, this does not necessarily mean that the pairwise distances of two node embeddings vary as much.
====
