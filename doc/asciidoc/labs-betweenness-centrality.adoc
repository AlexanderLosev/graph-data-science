[[algorithms-betweenness-centrality]]
= The Betweenness Centrality algorithm

[abstract]
--
This section describes the Betweenness Centrality algorithm in the Neo4j Labs Graph Algorithms library.
--

Betweenness centrality is a way of detecting the amount of influence a node has over the flow of information in a graph.
It is often used to find nodes that serve as a bridge from one part of a graph to another.


// TODO: If we want to call out the paper: http://www.algo.uni-konstanz.de/publications/b-fabc-01.pdf

[WARNING]
--
The Betweenness Centrality algorithm was developed by the Neo4j Labs team and is not officially supported.
--

In the following example, Alice is the main connection in the graph:

image::../images/betweenness_centrality.png[]

If Alice is removed, all connections in the graph would be cut off.
This makes Alice important, because she ensures that no nodes are isolated.

This section includes:

* <<algorithms-betweenness-centrality-context, History and explanation>>
* <<algorithms-betweenness-centrality-usecase, Use-cases - when to use the Betweenness Centrality algorithm>>
* <<algorithms-betweenness-centrality-limitations, Constraints - when not to use the Betweenness Centrality algorithm>>
* <<algorithms-betweenness-centrality-syntax, Syntax>>
* <<algorithms-betweenness-centrality-sample, Betweenness Centrality example>>
* <<algorithms-betweenness-centrality-approx, Sampled Betweenness Centrality>>
** <<algorithms-betweenness-centrality-ra_brandes, Sampled Betweenness Centrality example>>
* <<algorithms-betweenness-centrality-cp, Cypher projection>>


[[algorithms-betweenness-centrality-context]]
== History and explanation

The Betweenness Centrality algorithm calculates the shortest (weighted) path between every pair of nodes in a connected graph, using the breadth-first search algorithm.
Each node receives a score, based on the number of these shortest paths that pass through the node.
Nodes that most frequently lie on these shortest paths will have a higher betweenness centrality score.

The algorithm was given its first formal definition by Linton Freeman, in his 1971 paper http://moreno.ss.uci.edu/23.pdf["A Set of Measures of Centrality Based on Betweenness"^].
It was considered to be one of the "three distinct intuitive conceptions of centrality".


[[algorithms-betweenness-centrality-usecase]]
== Use-cases - when to use the Betweenness Centrality algorithm

* Betweenness centrality is used to research the network flow in a package delivery process, or telecommunications network.
  These networks are characterized by traffic that has a known target and takes the shortest path possible.
  This, and other scenarios, are described by Stephen P. Borgatti in http://www.analytictech.com/borgatti/papers/centflow.pdf["Centrality and network flow"].

* Betweenness centrality is used to identify influencers in legitimate, or criminal, organizations.
  Studies show that influencers in organizations are not necessarily in management positions, but instead can be found in brokerage positions of the organizational network.
  Removal of such influencers could seriously destabilize the organization.
  More detail can be found in http://archives.cerium.ca/IMG/pdf/Morselli_and_Roy_2008_.pdf["Brokerage qualifications in ringing operations"], by Carlo Morselli and Julie Roy.

* Betweenness centrality can be used to help microbloggers spread their reach on Twitter, with a recommendation engine that targets influencers that they should interact with in the future.
  This approach is described in ftp://ftp.umiacs.umd.edu/incoming/louiqa/PUB2012/RecMB.pdf["Making Recommendations in a Microblog to Improve the Impact of a Focal User"].


[[algorithms-betweenness-centrality-limitations]]
== Constraints - when not to use the Betweenness Centrality algorithm

* Betweeness centrality makes the assumption that all communication between nodes happens along the shortest path and with the same frequency, which isn't the case in real life.
  Therefore, it doesn't give us a perfect view of the most influential nodes in a graph, but rather a good representation.
  Newman explains this in more detail on page 186 of https://global.oup.com/academic/product/networks-9780199206650?cc=us&lang=en&[Networks: An Introduction^].

* For large graphs, exact centrality computation isn't practical.
  The fastest known algorithm for exactly computing betweenness of all the nodes requires at least `O(nm)` time for unweighted graphs, where `n` is the number of nodes and `m` is the number of relationships.
  Instead, we can use an approximation algorithm that works with a subset of nodes.


[[algorithms-betweenness-centrality-syntax]]
== Syntax

.The following will run the Betweenness Centrality algorithm and write back results:
[source, cypher]
----
CALL gds.alpha.betweenness.write(configuration: MAP)
YIELD nodes, minCentrality, maxCentrality, sumCentrality, loadMillis, computeMillis, writeMillis
----

.Parameters
[opts="header",cols="1,1,1,1,4"]
|===
| Name          | Type    | Default | Optional | Description
| configuration | map     | {}      | no       | Configuration parameters.
|===

.Configuration
[opts="header",cols="1,1,1,1,4"]
|===
| Name             | Type    | Default                | Optional | Description
| direction        | string  | OUTGOING               | yes      | The relationship direction to load from the graph. If 'BOTH', treats the relationships as undirected.
| writeProperty    | string  | 'centrality'           | yes      | The property name written back to.
| concurrency      | int     | 4                      | yes      | The number of concurrent threads used for running the algorithm. Also provides the default value for 'readConcurrency' and 'writeConcurrency'. This is dependent on the Neo4j edition; for more information, see <<system-requirements-cpu>>.
| readConcurrency  | int     | value of 'concurrency' | yes      | The number of concurrent threads used for reading the graph.
| writeConcurrency | int     | value of 'concurrency' | yes      | The number of concurrent threads used for writing the result.
|===

.Results
[opts="header",cols="1,1,6"]
|===
| Name          | Type | Description
| nodes         | int  | The number of nodes considered
| minCentrality | int  | The minimum centrality value
| maxCentrality | int  | The maximum centrality value
| sumCentrality | int  | The sum of all centrality values
| loadMillis    | int  | Milliseconds for loading data
| computeMillis | int  | Milliseconds for running the algorithm
| writeMillis   | int  | Milliseconds for writing result data back
|===


.The following will run the Betweenness Centrality algorithm and stream results:
[source,cypher]
----
CALL gds.alpha.betweenness.stream(configuration: MAP)
YIELD nodeId, centrality
----

.Parameters
[opts="header",cols="1,1,1,1,4"]
|===
| Name            | Type   | Default                | Optional | Description
| direction       | string | OUTGOING               | yes      | The relationship direction to load from the graph. If 'BOTH', treats the relationships as undirected.
| concurrency     | int    | 4                      | yes      | The number of concurrent threads used for running the algorithm. Also provides the default value for 'readConcurrency' and 'writeConcurrency'. This is dependent on the Neo4j edition; for more information, see <<system-requirements-cpu>>.
| readConcurrency | int    | value of 'concurrency' | yes      | The number of concurrent threads used for reading the graph.
|===

.Results
[opts="headers"]
|===
| Name        | Type  | Description
| node        | long  | Node ID
| centrality  | float | Betweenness centrality weight
|===


.The following will run the Sampled Betweenness Centrality algorithm and write back results:
[source,cypher]
----
CALL gds.alpha.betweenness.sampled.write(configuration: MAP)
YIELD nodes, minCentrality, maxCentrality, sumCentrality, loadMillis, computeMillis, writeMillis
----

.Parameters
[opts="header",cols="1,1,1,1,4"]
|===
| Name             | Type   | Default                | Optional | Description
| direction        | string | OUTGOING               | yes      | The relationship direction to load from the graph. If 'BOTH', treats the relationships as undirected.
| writeProperty    | string | 'centrality'           | yes      | The property name written back to.
| strategy         | string | 'random'               | yes      | The node selection strategy.
| probability      | float  | log10(N) / e^2         | yes      | The probability a node is selected. Values between 0 and 1. If 1, selects all nodes and works like original Brandes algorithm.
| maxDepth         | int    | Integer.MAX            | yes      | The depth of the shortest paths traversal.
| concurrency      | int    | 4                      | yes      | The number of concurrent threads used for running the algorithm. Also provides the default value for 'readConcurrency' and 'writeConcurrency'. This is dependent on the Neo4j edition; for more information, see <<system-requirements-cpu>>.
| readConcurrency  | int    | value of 'concurrency' | yes      | The number of concurrent threads used for reading the graph.
| writeConcurrency | int    | value of 'concurrency' | yes      | The number of concurrent threads used for writing the result.
|===

.Results
[opts="header",cols="1,1,6"]
|===
| Name          | Type | Description
| nodes         | int  | The number of nodes considered
| minCentrality | int  | The minimum centrality value
| maxCentrality | int  | The maximum centrality value
| sumCentrality | int  | The sum of all centrality values
| loadMillis    | int  | Milliseconds for loading data
| computeMillis | int  | Milliseconds for running the algorithm
| writeMillis   | int  | Milliseconds for writing result data back
|===


.The following will run the Sampled Betweenness Centrality algorithm and stream results:
[source,cypher]
----
CALL gds.alpha.betweenness.sampled.stream(configuration: MAP)
YIELD nodeId, centrality
----

.Parameters
[opts="header",cols="1,1,1,1,4"]
|===
| Name            | Type   | Default                | Optional | Description
| label           | string | null                   | yes      | The label to load from the graph. If null, load all nodes.
| relationship    | string | null                   | yes      | The relationship type to load from the graph. If null, load all relationships.
| concurrency     | int    | available CPUs         | yes      | The number of concurrent threads used for running the algorithm. Also provides the default value for 'readConcurrency'.
| readConcurrency | int    | value of 'concurrency' | yes      | The number of concurrent threads used for reading the graph.
| direction       | string | outgoing               | yes      | The relationship direction to load from the graph. If 'both', treats the relationships as undirected.
| strategy        | string | 'random'               | yes      | The node selection strategy.
| probability     | float  | log10(N) / e^2         | yes      | The probability a node is selected. Values between 0 and 1. If 1, selects all nodes and works like original Brandes algorithm.
| maxDepth        | int    | Integer.MAX            | yes      | The depth of the shortest paths traversal.
|===

.Results
[opts="headers"]
|===
| Name       | Type  | Description
| node       | long  | Node ID.
| centrality | float | Betweenness centrality weight.
|===


[[algorithms-betweenness-centrality-sample]]
== Betweenness Centrality algorithm sample

People with high betweenness tend to be the innovators and brokers in social networks.
They combine different perspectives, transfer ideas between groups, and get power from their ability to make introductions and pull strings.

.The following will create a sample graph:
[source, cypher]
----
CREATE (alice:User {name: 'Alice'}),
       (bridget:User {name: 'Bridget'}),
       (charles:User {name: 'Charles'}),
       (doug:User {name: 'Doug'}),
       (mark:User {name: 'Mark'}),
       (michael:User {name: 'Michael'}),
       (alice)-[:MANAGE]->(bridget),
       (alice)-[:MANAGE]->(charles),
       (alice)-[:MANAGE]->(doug),
       (mark)-[:MANAGE]->(alice),
       (charles)-[:MANAGE]->(michael)
----

.The following will run the algorithm and stream results:
[source, cypher]
----
CALL gds.alpha.betweenness.stream({
  nodeProjection: 'User',
  relationshipProjection: 'MANAGE',
  direction: 'OUTGOING'
})
YIELD nodeId, centrality
RETURN gds.util.asNode(nodeId).name AS user, centrality
ORDER BY centrality DESC
----

.Results
[opts="header", cols="1,1"]
|===
| user    | centrality
| Alice   | 4
| Charles | 2
| Bridget | 0
| Doug    | 0
| Mark    | 0
| Michael | 0
|===

We can see that Alice is the main broker in this network, and Charles is a minor broker.
The others don't have any influence, because all the shortest paths between pairs of people go via Alice or Charles.


.The following will run the algorithm and write back results:
[source, cypher]
----
CALL gds.alpha.betweenness.write({
  nodeProjection: 'User',
  relationshipProjection: 'MANAGE',
  direction: 'OUTGOING',
  writeProperty: 'centrality'
}) YIELD nodes, minCentrality, maxCentrality, sumCentrality
----

.Results
[opts="header"]
|===
| nodes | minCentrality | maxCentrality | sumCentrality
| 6     | 0.0           | 4.0           | 6.0
|===


[[algorithms-betweenness-centrality-approx]]
== Approximation of Betweenness Centrality

As mentioned above, calculating the exact betweenness centrality on large graphs can be very time consuming.
Therefore, you might choose to use an approximation algorithm that will run much quicker, and still provide useful information.


[[algorithms-betweenness-centrality-ra_brandes]]
=== Sampled Betweenness Centrality algorithm

The RA-Brandes algorithm is the best known algorithm for calculating an approximate score for betweenness centrality.
Rather than calculating the shortest path between every pair of nodes, the RA-Brandes algorithm considers only a subset of nodes.
Two common strategies for selecting the subset of nodes are:

random::
  Nodes are selected uniformly, at random, with defined probability of selection.
  The default probability is `log10(N) / e^2`.
  If the probability is 1, then the algorithm works the same way as the normal Betweenness Centrality algorithm, where all nodes are loaded.

degree::
  First, the mean degree of the nodes is calculated, and then only the nodes whose degree is higher than the mean are visited (i.e. only dense nodes are visited).

As a further optimisation, you can choose to limit the depth used by the shortest path algorithm.
This can be controlled by the `maxDepth` parameter.


.The following will run the algorithm and stream results:
[source,cypher]
----
CALL gds.alpha.betweenness.sampled.stream({
  nodeProjection: 'User',
  relationshipProjection: 'MANAGE',
  strategy: 'random',
  probability: 1.0,
  maxDepth: 1,
  direction: 'OUTGOING'
}) YIELD nodeId, centrality
RETURN gds.util.asNode(nodeId).name AS user, centrality
ORDER BY centrality DESC
----

.Results
[opts="header",cols="1,1"]
|===
| user | centrality
| Alice | 3
| Charles | 1
| Bridget | 0
| Doug | 0
| Mark | 0
| Michael | 0
|===

Alice is still the main broker in the network, and Charles is a minor broker, although their centrality score has reduced as the algorithm only considers relationships at a depth of 1.
The others don’t have any influence, because all the shortest paths between pairs of people go via Alice or Charles.


.The following will run the algorithm and write back results:
[source,cypher]
----
CALL gds.alpha.betweenness.sampled.write({
  nodeProjection: 'User',
  relationshipProjection: 'MANAGE',
  strategy: 'random',
  probability: 1.0,
  writeProperty: 'centrality',
  maxDepth: 1,
  direction: 'OUTGOING'
})
YIELD nodes, minCentrality, maxCentrality, sumCentrality
----

.Results
[opts="header"]
|===
| nodes | minCentrality | maxCentrality | sumCentrality
| 6     | 0.0           | 3.0           | 4.0
|===


[[algorithms-betweenness-centrality-cp]]
== Cypher projection

include::projected-graph-model/cypher-projection.adoc[tag=explanation]

[source, cypher]
----
CALL gds.alpha.betweenness.write({
  nodeQuery: 'MATCH (p:User) RETURN id(p) as id',
  relationshipQuery: 'MATCH (p1:User)-[:MANAGE]->(p2:User) RETURN id(p1) as source, id(p2) as target'
}) YIELD nodes, minCentrality, maxCentrality, sumCentrality
----

