[[algorithms-wcc]]
= The Weakly Connected Components algorithm

[abstract]
--
This section describes the Weakly Connected Components (WCC) algorithm in the Neo4j Graph Algorithms library.
--

This section includes:

* <<algorithms-wcc-intro, Introduction>>
* <<algorithms-wcc-syntax, Syntax>>
* <<algorithms-wcc-example, Examples>>
* <<algorithms-wcc-usage-details, Usage Details>>

* <<algorithms-wcc-context, History and explanation>>
* <<algorithms-wcc-sample, Connected Components algorithm sample>>
** <<algorithms-wcc-sample-unweighted, Unweighted version>>
** <<algorithms-wcc-sample-weighted, Weighted version>>
** <<algorithms-wcc-example-seeding, Using seed communities>>
* <<algorithms-wcc-hgp, Huge graph projection>>
* <<algorithms-wcc-cp, Cypher projection>>
* <<algorithms-wcc-imp, Implementations>>
* <<algorithms-unionfind-memory-requirements, Memory Requirements>>


[[algorithms-wcc-intro]]
== Introduction

The WCC algorithm finds sets of connected nodes in an undirected graph, where all nodes in the same set form a connected component.
// Don't call out to Labs; let Labs call to us
// It differs from the Strongly Connected Components algorithm (SCC) because it only needs a path to exist between pairs of nodes in one direction, whereas SCC needs a path to exist in both directions.
WCC is often used early in an analysis to understand the structure of a graph.

WCC was previously known as Union Find.
Currently, the WCC algorithm still uses the syntax of `algo.unionFind`.

WCC can be used to keep track of clusters of database records, as part of the de-duplication process - an important task in master data management applications.
WCC can also be used to analyse citation networks.

For more information on this algorithm, see:

* http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.28.8405["An efficient domain-independent algorithm for detecting approximately duplicate database records"^].
* One study uses WCC to work out how well connected the network is, and then to see whether the connectivity remains if 'hub' or 'authority' nodes are moved from the graph: https://link.springer.com/article/10.1007%2Fs10115-003-0128-3["Characterizing and Mining Citation Graph of Computer Science Literature"^]


[NOTE]
====
Running this algorithm requires sufficient memory availability.
Before running this algorithm, we recommend that you read <<memory-requirements>>.
====


[[algorithms-wcc-syntax]]
== Syntax

.The following will load a graph, run the algorithm, and write back results:
[source, cypher]
----
CALL algo.unionFind(label: String, relationship: String, {
  threshold: 0.42,
  defaultValue: 1.0,
  write: true,
  writeProperty: 'partition',
  weightProperty: 'weight',
  concurrency: 4
})
YIELD nodes, setCount, loadMillis, computeMillis, writeMillis
----

.Parameters
[opts="header",cols="1,1,1m,1,4"]
|===
| Name         | Type    | Default | Optional | Description
| node label   | string  | null    | yes      | The node label to load from the graph. If null, load all nodes.
| relationship | string  | null    | yes      | The relationship type to load from the graph. If null, load all relationships.
| config       | map     | {}      | yes      | Additional configuration, see below.
|===

.Configuration
[opts="header",cols="1m,1,1,1,4"]
|===
| Name              | Type    | Default                   | Optional | Description
| concurrency       | int     | available CPUs            | yes      | The number of concurrent threads used for running the algorithm. Also provides the default value for 'readConcurrency' and 'writeConcurrency'. This is dependent on the Neo4j edition; for more information, see <<system-requirements-cpu>>.
| readConcurrency   | int     | value of 'concurrency'    | yes      | The number of concurrent threads used for reading the graph.
| writeConcurrency  | int     | value of 'concurrency'    | yes      | The number of concurrent threads used for writing the result.
| weightProperty    | string  | `null`                    | yes      | The property name that contains weight. If null, treats the graph as unweighted. Must be numeric.
| seedProperty      | string  | n/a                       | yes      | Used to set the initial community for a node. The property value needs to be a number.
| write             | boolean | `true`                    | yes      | Specifies if the result should be written back as a node property.
| writeProperty     | string  | `'partition'`             | yes      | The property name written back the ID of the partition particular node belongs to.
| threshold         | float   | `null`                    | yes      | The value of the weight above which the relationship is not thrown away.
| defaultValue      | float   | `null`                    | yes      | The default value of the weight in case it is missing or invalid.
| consecutiveIds    | boolean | `false`                   | yes      | Community identifiers are mapped into a consecutive id space (requires additional memory).
| graph             | string  | `'huge'`                  | yes      | Use `'huge'` when describing the subset of the graph with label and relationship type parameter. Use `'cypher'` for describing the subset using a Cypher query for nodes and relationships.
|===

.Results
[opts="header",cols="1m,1,6"]
|===
| Name          | Type | Description
| loadMillis    | int  | Milliseconds for loading data.
| computeMillis | int  | Milliseconds for running the algorithm.
| writeMillis   | int  | Milliseconds for writing result data back.

| postProcessingMillis    | int  | Milliseconds for computing percentiles and community count.
| nodes | int | The number of nodes considered.
| communityCount | int  | The number of communities found.

| p1                   | double  | The 1 percentile of community size.
| p5                   | double  | The 5 percentile of community size.
| p10                   | double  | The 10 percentile of community size.
| p25                   | double  | The 25 percentile of community size.
| p50                   | double  | The 50 percentile of community size.
| p75                   | double  | The 75 percentile of community size.
| p90                   | double  | The 90 percentile of community size.
| p95                   | double  | The 95 percentile of community size.
| p99                   | double  | The 99 percentile of community size.
| p100                  | double  | The 100 percentile of community size.

| write | boolean | Specifies if the result was written back as a node property.
| writeProperty | string | The property name written back to.
|===


.The following will run the algorithm and stream results:
[source, cypher]
----
CALL algo.unionFind.stream(label: String, relationship: String, {
    weightProperty: 'weight',
    threshold: 0.42,
    defaultValue: 1.0,
    concurrency: 4
})
YIELD nodeId, setId
----

.Parameters
[opts="header",cols="1,1,1,1,4"]
|===
| Name              | Type    | Default        | Optional | Description
| node label        | string  | `null`         | yes      | The node label to load from the graph. If null, load all nodes.
| relationship type | string  | `null`         | yes      | The relationship type to load from the graph. If null, load all relationships.
| config            | map     | `{}`           | yes      | Additional configuration, see below.
|===

.Configuration
[opts="header",cols="1m,1,1,1,4"]
|===
| Name              | Type    | Default                   | Optional | Description
| concurrency       | int     | available CPUs            | yes      | The number of concurrent threads used for running the algorithm. Also provides the default value for 'readConcurrency'.
| readConcurrency   | int     | value of 'concurrency'    | yes      | The number of concurrent threads used for reading the graph.
| weightProperty    | string  | `null`                    | yes      | The property name that contains weight. If null, treats the graph as unweighted. Must be numeric.
| seedProperty      | string  | n/a                       | yes      | Used to set the initial community for a node. The property value needs to be a number.
| threshold         | float   | `null`                    | yes      | The value of the weight above which the relationship is not thrown away.
| defaultValue      | float   | `null`                    | yes      | The default value of the weight in case it is missing or invalid.
| consecutiveIds    | boolean | `false`                   | yes      | Community identifiers are mapped into a consecutive id space (requires additional memory).
| graph             | string  | `'huge'`                  | yes      | Use `'huge'` when describing the subset of the graph with label and relationship-type parameter. Use `'cypher'` for describing the subset using a Cypher query for nodes and relationships.
|===

.Results
[opts="header",cols="1m,1,6"]
|===
| Name   | Type | Description
| nodeId | int  | Node ID
| setId  | int  | Partition ID
|===


[[algorithms-wcc-sample]]
== Connected Components algorithm sample

If we recall that an undirected graph is connected if, for every pair of vertices there is a path in the graph between those vertices.
A connected component of an undirected graph is a maximal connected subgraph of the graph.
That means that the direction of the relationships in our graph are ignored - we treat the graph as undirected.

We have two implementations of the Connected Components algorithm.
The first treats the graph as unweighted and the second treats it as weighted, where you can define the threshold of the weight above which relationships are included.

image::connected_components.png[]

.The following will create a sample graph:
[source, cypher]
----
include::scripts/connected-components.cypher[tag=create-sample-graph]
----


[[algorithms-wcc-sample-unweighted]]
=== Unweighted version

.The following will run the algorithm and stream results:
[source, cypher]
----
include::scripts/connected-components.cypher[tag=unweighted-stream-sample-graph]
----
.The following will run the algorithm and write back results:
[source, cypher]
----
include::scripts/connected-components.cypher[tag=unweighted-write-sample-graph]
----

// tag::unweighted-stream-sample-graph-result[]
.Results
[opts="header",cols="1,1"]
|===
| Name    | Partition
| Alice   | 0
| Charles | 0
| Bridget | 0
| Michael | 4
| Doug    | 4
| Mark    | 4
|===
// end::unweighted-stream-sample-graph-result[]

// tag::unweighted-stream-sample-graph-explanation[]
We have two distinct group of users, that have no link between them.

The first group contains Alice, Charles, and Bridget, while the second group contains Michael, Doug, and Mark.
// end::unweighted-stream-sample-graph-explanation[]

.The following will check the number and size of partitions, using Cypher:
[source, cypher]
----
include::scripts/connected-components.cypher[tag=check-results-sample-graph]
----


[[algorithms-wcc-sample-weighted]]
=== Weighted version

If you define the property that holds the weight (`weightProperty`) and the threshold, it means the nodes are only connected, if the threshold on the weight of the relationship is high enough, otherwise the relationship is thrown away.

.The following will run the algorithm and stream results:
[source, cypher]
----
include::scripts/connected-components.cypher[tag=weighted-stream-sample-graph]
----

.The following will run the algorithm and write back results:
[source, cypher]
----
include::scripts/connected-components.cypher[tag=weighted-write-sample-graph]
----

// tag::weighted-stream-sample-graph-result[]
.Results
[opts="header",cols="1,1"]
|===
| Name    | Partition
| Alice   | 0
| Charles | 0
| Bridget | 1
| Michael | 4
| Doug    | 4
| Mark    | 4
|===
// end::weighted-stream-sample-graph-result[]

// tag::weighted-stream-sample-graph-explanation[]
In this case we can see that, because the weight of the relationship between Bridget and Alice is only 0.5, the relationship is ignored by the algorithm, and Bridget ends up in her own component.
// end::weighted-stream-sample-graph-explanation[]


[[algorithms-wcc-example]]
== Example usage

As mentioned above, connected components are an essential step in preprocessing your data.
One reason is that most centralities suffer from disconnected components, or you just want to find disconnected groups of nodes.
Int his example, Yelp's social network will be used to demonstrate how to proceed when dealing with real world data.
A typical social network consists of one big component and a number of small disconnected components.

.The following will get the count of connected components:
[source, cypher]
----
include::scripts/connected-components.cypher[tag=count-component-yelp]
----

We get back the count of disconnected components being 18512 if we do not count users without friends.
Let's now check the size of top 20 components to get a better picture:

.The following will get the size of top 20 components:
[source, cypher]
----
include::scripts/connected-components.cypher[tag=top-20-component-yelp]
----

The biggest component has 8938630 out of total 8981389 (99,5%).
It is quite high, but not shocking, as we have a friendship social network where we can expect small world effect and 6 degree of separation rule, where you can get to any person in a social network, just depends how long is the path.

We can now move on to next step of analysis and run centralities on only the biggest components, so that our results will be more accurate.
We will write back the results to the node, and use centralities with Cypher loading, or set a new community identifier for the biggest component.


[[algorithms-wcc-example-seeding]]
=== Using seed communities

It is possible to define preliminary communities of nodes using the `seedProperty` parameter.
This is helpful if we want to retain communities from a previous run.
The property value needs to be a number.

The algorithm first checks if there is a seed community assigned to the node.
If there is one, that community is used.
Otherwise, a new unique community is assigned to the node.

Once every node has a community, the algorithm runs and merges communities of nodes that are connected.
When merging communities, the resulting community is always the one with the lower community id.

[NOTE]
If the `seedProperty` option is the same as the `writeProperty` option,
the algorithm only writes properties for nodes where the community has changed.
If they differ, the algorithm writes properties for all nodes.


[[algorithms-wcc-hgp]]
== Huge graph projection

include::huge-projection.adoc[tag=explanation]

.Set `graph:'huge'` in the config:

[source, cypher]
----
include::scripts/connected-components.cypher[tag=huge-projection]
----


[[algorithms-wcc-cp]]
== Cypher projection

include::projected-graph-model/cypher-projection.adoc[tag=explanation]

.Set `graph:'cypher'` in the config:

[source, cypher]
----
include::scripts/connected-components.cypher[tag=cypher-loading]
----


[[algorithms-wcc-imp]]
== Implementation

`algo.unionFind`

* If a threshold configuration parameter is supplied, only relationships with a property value higher than the threshold are merged.
* Parallel `Union Find`, using `ExecutorService` only.
* Algorithm based on the idea that `DisjointSetStruct` can be built using just a partition of the nodes, which are then merged pairwise.
* The implementation is based on a queue which acts as a buffer for each computed `DisjointSetStruct`.
  As long as there are more elements on the queue, the algorithm takes two, merges them, and adds its result to the queue until only 1 element remains.


[[algorithms-unionfind-memory-requirements]]
== Memory Requirements for the Union Find algorithm
:algorithm: "unionFind"

We can use the <<algo-memrec-procedure>> to compute the memory requirements of running graph algorithms.

.The following returns the memory requirements for running Louvain on the Huge Graph:
:graph: "huge"
include::memrec.adoc[tags=overview]

.Results
[opts="header",cols="1,1,2"]
|===
| Nodes | Relationships | Required Memory
| 6 | 7 | [299 KiB ... 300 KiB]
|===

We can also get a break down of where that memory is assigned from the `mapView` field.

.The following returns the memory break down for running Louvain on the Huge Graph:
:graph: "huge"
include::memrec.adoc[tags=component]

.Results
[opts="header",cols="1,2"]
|===
| Component | Memory Usage
| Louvain | [3176 Bytes ... 4072 Bytes]
| HugeGraph | 296 KiB
|===

Below are the memory requirements for various sample datasets.


=== Pokec

This dataset contains people and friends relationships from https://snap.stanford.edu/data/soc-Pokec.html[Pokec^], the most popular online social network in Slovakia.

.Memory Usage
[opts="header", cols="1,1,1,2,2,2"]
|===
| Graph Type | Nodes | Relationships | Required Memory | In Memory Graph | Algorithm
| Huge | 1,632,803 | 30,622,564 | 	[274 MiB...330 MiB] | [74 MiB...130 MiB] | 199 MiB
|===


=== Dbpedia

This dataset contains Wikipedia pages and the links between them.
Instructions for importing this dataset are available from https://github.com/jexp/graphipedia[jexp/graphipedia^].

.Memory Usage
[opts="header", cols="1,1,1,2,2,2"]
|===
| Graph Type | Nodes | Relationships | Required Memory | In Memory Graph | Algorithm
| Huge | 11,474,730 | 116,601,029 | 	[1839 MiB...2057 MiB] | [438 MiB...657 MiB] | 1400 MiB
|===

=== Twitter 2010

This dataset contains users and followers from a crawl of Twitter presented by Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon in “What is Twitter, a Social Network or a News Media?”

.Memory Usage
[opts="header", cols="1,1,1,2,2,2"]
|===
| Graph Type | Nodes | Relationships | Required Memory | In Memory Graph | Algorithm
| Huge | 41,652,230 | 1,468,365,182 | 	[7669 MiB...10449 MiB] | [3570 MiB...8638 MiB]   | 5084 MiB
|===

=== Friendster

This dataset contains people and friends relationships from https://snap.stanford.edu/data/com-Friendster.html[Friendster^], the online gaming network.

.Memory Usage
[opts="header", cols="1,1,1,2,2,2"]
|===
| Graph Type | Nodes | Relationships | Required Memory | In Memory Graph | Algorithm
| Huge | 65,608,366 | 1,806,067,135 | 	[11579 MiB...16 GiB]  | [3570 MiB...8638 MiB]   | 8008 MiB
|===


ifndef::env-docs[]
== References

// tag::references[]

* http://math.hws.edu/eck/cs327_s04/chapter9.pdf
* https://en.wikipedia.org/wiki/Connected_component_(graph_theory)

// end::references[]
endif::env-docs[]

ifdef::implementation[]
// tag::implementation[]


== Implementation details

:leveloffset: +1
// copied from: https://github.com/neo4j-contrib/neo4j-graph-algorithms/issues/79

_Connected Components_ or _Union Find_ basically finds sets of connected nodes where each node is reachable from any other node in the same set. One implementation also evaluates a Predicate on each relation which allows partitioning of the graph based on Relationships and Properties.

## Progress

- [x] single threaded implementation
- [x] tests
- [x] simple benchmark
- [x] implement procedure
- [x] benchmark on bigger graphs
- [x] parallelization
- [x] evaluation

## Requirements

`AllRelationshipIterator` & `Weights`

## Data structured involved

We use a disjoint-set-structure which is based on a parent-array-tree. The DSS can be used to efficiently ask if two nodes are reachable by each other. [More](https://en.wikipedia.org/wiki/Disjoint-set_data_structure)

## ToDo

### benchmark

Implement benchmark on big graph &

- stream nodeId-setId pairs
- calculate setSize-setCount


### parallelization

One approach to parallelize _Union Find_ might be _relationship partitioning_ where each thread performs the execution into it's own DSS instance on a subset of relationships. So each thread calculates a distinct set of unions. Later we can merge each DSS pairwise which can also be perfomed in parallel. Nonetheless the memory consumption might be high due to the preallocated array in DSS. We could also switch to a growing container if this is a problem.

### evaluation

- Performance tests on different dataset sizes / level of concurrency


== Details

- writes a cluster-id to each node representing the a connected component where each node
is reachable from any other node


=== algo.unionFind

- if a threshold configuration parameter is supplied only relationships with a property value higher then the threshold
are merged


=== algo.unionFind.queue

- parallel Union Find using ExecutorService only.
- Algorithm based on the idea that DisjointSetStruct can be built using just a partition of the nodes
which are then merged pairwise.
- The implementation is based on a queue which acts as a buffer for each computed DSS. As long as there are
more elements on the queue the algorithm takes two, merges them and adds its result to the queue until only
1 element remains.


=== algo.unionFind.forkJoinMerge

-  Like in *exp1* the resulting DSS of each node-partition is merged by the ForkJoin pool while
the calculation of the DSS is done by the ExecutorService.


=== algo.unionFind.forkJoin

- calculation and merge using forkJoinPool

// end::implementation[]
endif::implementation[]
